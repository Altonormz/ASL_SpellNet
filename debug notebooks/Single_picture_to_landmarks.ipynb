{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7131c36f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "import os\n",
    "import gc\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cb967919",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n"
     ]
    }
   ],
   "source": [
    "mp_hands = mp.solutions.hands\n",
    "hands = mp_hands.Hands()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f587c25f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def preprocess_image(img_path):\n",
    "    # Read image and change from default BGR to RGB\n",
    "\n",
    "    img = cv2.imread(img_path)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    if img is None:\n",
    "        print('No picture was found at', img_path)\n",
    "    return img\n",
    "\n",
    "def process_image(img, holistic_model):\n",
    "    # Return the results from the mediapipe model\n",
    "    img.flags.writeable = False\n",
    "    results = holistic_model.process(img)\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b8c29ca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_row_dict(results, img_name):\n",
    "    # Return a dictionary with picture name and the landmarks of the hand.\n",
    "    # Note this works only if there's one hand in picture.\n",
    "    for hand in results.multi_hand_landmarks:\n",
    "        x_landmarks = []\n",
    "        y_landmarks = []\n",
    "        z_landmarks = []\n",
    "        for id, lm in enumerate(hand.landmark):\n",
    "            x_landmarks.append(lm.x)\n",
    "            y_landmarks.append(lm.y)\n",
    "            z_landmarks.append(lm.z)\n",
    "\n",
    "        landmarks = x_landmarks + y_landmarks + z_landmarks\n",
    "        data = {'image_name': img_name}\n",
    "        data.update({f'{dim}_left_{i}': landmarks[i + 21*j] for j,dim in enumerate(['x', 'y', 'z']) for i in range(21)})\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c5f08b7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_hands = mp.solutions.hands\n",
    "hands = mp_hands.Hands()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "9c47a0b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE = 'A0029_test.jpg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "ca82b875",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ WARN:0@480.530] global loadsave.cpp:244 findDecoder imread_('A0029_test.jpg'): can't open/read file: check file path/integrity\n"
     ]
    },
    {
     "ename": "error",
     "evalue": "OpenCV(4.7.0) /io/opencv/modules/imgproc/src/color.cpp:182: error: (-215:Assertion failed) !_src.empty() in function 'cvtColor'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[59], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m image \u001b[38;5;241m=\u001b[39m \u001b[43mpreprocess_image\u001b[49m\u001b[43m(\u001b[49m\u001b[43mIMAGE\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m results \u001b[38;5;241m=\u001b[39m process_image(image, hands)\n\u001b[1;32m      3\u001b[0m results\u001b[38;5;241m.\u001b[39mmulti_hand_landmarks\n",
      "Cell \u001b[0;32mIn[3], line 5\u001b[0m, in \u001b[0;36mpreprocess_image\u001b[0;34m(img_path)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpreprocess_image\u001b[39m(img_path):\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;66;03m# Read image and change from default BGR to RGB\u001b[39;00m\n\u001b[1;32m      4\u001b[0m     img \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mimread(img_path)\n\u001b[0;32m----> 5\u001b[0m     img \u001b[38;5;241m=\u001b[39m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcvtColor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCOLOR_BGR2RGB\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m img \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m      7\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNo picture was found at\u001b[39m\u001b[38;5;124m'\u001b[39m, img_path)\n",
      "\u001b[0;31merror\u001b[0m: OpenCV(4.7.0) /io/opencv/modules/imgproc/src/color.cpp:182: error: (-215:Assertion failed) !_src.empty() in function 'cvtColor'\n"
     ]
    }
   ],
   "source": [
    "\n",
    "image = preprocess_image(IMAGE)\n",
    "results = process_image(image, hands)\n",
    "results.multi_hand_landmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "efd4a91c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'image_name': 'A0029_test.jpg',\n",
       " 'x_left_0': 0.31285110116004944,\n",
       " 'x_left_1': 0.4129948318004608,\n",
       " 'x_left_2': 0.4959872364997864,\n",
       " 'x_left_3': 0.5288628935813904,\n",
       " 'x_left_4': 0.5722736716270447,\n",
       " 'x_left_5': 0.4683475196361542,\n",
       " 'x_left_6': 0.48850780725479126,\n",
       " 'x_left_7': 0.4585871696472168,\n",
       " 'x_left_8': 0.43907430768013,\n",
       " 'x_left_9': 0.40560394525527954,\n",
       " 'x_left_10': 0.4271419048309326,\n",
       " 'x_left_11': 0.4061613082885742,\n",
       " 'x_left_12': 0.3961446285247803,\n",
       " 'x_left_13': 0.3445402681827545,\n",
       " 'x_left_14': 0.36204278469085693,\n",
       " 'x_left_15': 0.3534768223762512,\n",
       " 'x_left_16': 0.3523853123188019,\n",
       " 'x_left_17': 0.2812415361404419,\n",
       " 'x_left_18': 0.30552682280540466,\n",
       " 'x_left_19': 0.3083643913269043,\n",
       " 'x_left_20': 0.3113285005092621,\n",
       " 'y_left_0': 0.5703998804092407,\n",
       " 'y_left_1': 0.5541518330574036,\n",
       " 'y_left_2': 0.4758254587650299,\n",
       " 'y_left_3': 0.3941381871700287,\n",
       " 'y_left_4': 0.34925752878189087,\n",
       " 'y_left_5': 0.3926754295825958,\n",
       " 'y_left_6': 0.3358415365219116,\n",
       " 'y_left_7': 0.3953510522842407,\n",
       " 'y_left_8': 0.4508679211139679,\n",
       " 'y_left_9': 0.3781857490539551,\n",
       " 'y_left_10': 0.31180134415626526,\n",
       " 'y_left_11': 0.39102280139923096,\n",
       " 'y_left_12': 0.45572635531425476,\n",
       " 'y_left_13': 0.37555959820747375,\n",
       " 'y_left_14': 0.3210253417491913,\n",
       " 'y_left_15': 0.4111911356449127,\n",
       " 'y_left_16': 0.4722732603549957,\n",
       " 'y_left_17': 0.3844369649887085,\n",
       " 'y_left_18': 0.3444472551345825,\n",
       " 'y_left_19': 0.4134063720703125,\n",
       " 'y_left_20': 0.46166500449180603,\n",
       " 'z_left_0': -5.551838739847881e-07,\n",
       " 'z_left_1': -0.026652885600924492,\n",
       " 'z_left_2': -0.03183263540267944,\n",
       " 'z_left_3': -0.03718956187367439,\n",
       " 'z_left_4': -0.03842082992196083,\n",
       " 'z_left_5': -0.0055483682081103325,\n",
       " 'z_left_6': -0.05054774135351181,\n",
       " 'z_left_7': -0.073096863925457,\n",
       " 'z_left_8': -0.0782933384180069,\n",
       " 'z_left_9': -0.006084728520363569,\n",
       " 'z_left_10': -0.05842805281281471,\n",
       " 'z_left_11': -0.0693536028265953,\n",
       " 'z_left_12': -0.060324907302856445,\n",
       " 'z_left_13': -0.013780693523585796,\n",
       " 'z_left_14': -0.07063601166009903,\n",
       " 'z_left_15': -0.0620558001101017,\n",
       " 'z_left_16': -0.03766356408596039,\n",
       " 'z_left_17': -0.022554367780685425,\n",
       " 'z_left_18': -0.06454546749591827,\n",
       " 'z_left_19': -0.05722133815288544,\n",
       " 'z_left_20': -0.038403358310461044}"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_row_dict(results, IMAGE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d8a247b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa613406",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
